# ============================================================
# Claude Telegram Relay — Environment Variables
# ============================================================
# Copy to .env:  cp .env.example .env
# Then fill in your values below.
# ============================================================

# --- REQUIRED: Telegram ---

# Bot token from @BotFather
TELEGRAM_BOT_TOKEN=your_bot_token_from_botfather

# Your Telegram user ID (from @userinfobot)
TELEGRAM_USER_ID=your_telegram_user_id

# --- REQUIRED: Supabase (persistent memory) ---

# Project URL (looks like https://abc123.supabase.co)
SUPABASE_URL=your_project_url

# anon public key (starts with eyJ...)
SUPABASE_ANON_KEY=your_anon_key

# --- RECOMMENDED: Personalization ---

# Your first name
USER_NAME=Your Name

# Your timezone (IANA format: America/New_York, Europe/Berlin, etc.)
USER_TIMEZONE=UTC

# --- OPTIONAL: Paths ---

# Claude CLI path (auto-detected if in PATH)
# CLAUDE_PATH=claude

# Working directory for Claude (defaults to relay's own directory)
# PROJECT_DIR=/path/to/your/project

# Relay data directory (defaults to ~/.claude-relay)
# RELAY_DIR=~/.claude-relay

# --- OPTIONAL: Voice Transcription ---

# Google Gemini API key (free tier: ai.google.dev)
# GEMINI_API_KEY=your_gemini_key

# --- OPTIONAL: Voice Replies (ElevenLabs TTS) ---

# ElevenLabs API key (elevenlabs.io)
# ELEVENLABS_API_KEY=your_elevenlabs_key

# Voice ID (defaults to Rachel if not set)
# ELEVENLABS_VOICE_ID=21m00Tcm4TlvDq8ikWAM

# --- OPTIONAL: Phone Calls (ElevenLabs + Twilio) ---

# ElevenLabs Conversational AI Agent ID
# ELEVENLABS_AGENT_ID=your_agent_id

# Twilio phone number ID (from ElevenLabs dashboard)
# ELEVENLABS_PHONE_NUMBER_ID=your_phone_number_id

# Your phone number (E.164 format: +1234567890)
# USER_PHONE_NUMBER=+1234567890

# --- OPTIONAL: Forum Agents ---

# Telegram group chat ID with Forum Topics enabled (negative number)
# TELEGRAM_FORUM_GROUP_ID=

# --- OPTIONAL: Fallback AI Providers ---

# OpenRouter API key (openrouter.ai — access to many models)
# OPENROUTER_API_KEY=your_openrouter_key

# OpenRouter model (default: anthropic/claude-sonnet-4)
# OPENROUTER_MODEL=anthropic/claude-sonnet-4

# Local Ollama endpoint (default: http://localhost:11434)
# OLLAMA_URL=http://localhost:11434

# Ollama model name (default: llama3.2)
# OLLAMA_MODEL=llama3.2

# Enable/disable fallback chain (default: true)
# FALLBACK_ENABLED=true

# --- OPTIONAL: VPS Deployment ---

# VPS IP address (used by deploy scripts, not the bot)
# VPS_HOST=
# VPS_USER=deploy

# --- OPTIONAL: Health Check ---

# HTTP port for /health endpoint (default: 3000)
# HEALTH_PORT=3000
